{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise(sentence):\n",
    "    words = sentence.split()\n",
    "    result = []\n",
    "    for word in words:\n",
    "        tmp = word[0] + ''.join([word[i] for i in range(1, len(word)) if word[i] != word[i - 1]])\n",
    "        if tmp == '스로':\n",
    "            tmp = '스스로'\n",
    "        result.append(tmp)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'숙문을 취소하고 싶은데 가게 사장님 높서 전화를로 안 받아요.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revise('숙문을 취소하고  싶은데  가게  사장님 높서  전화를로 안안  받아요.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\lincall-ai\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Coding\\lincall-ai\\.venv\\lib\\site-packages\\torchaudio\\extension\\extension.py:14: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import librosa\n",
    "from kospeech.vocabs.ksponspeech import KsponSpeechVocabulary\n",
    "\n",
    "class STT:\n",
    "    device = \"cpu\"\n",
    "    model_path = \"./STT_model.pt\"\n",
    "    vocab = KsponSpeechVocabulary('./aihub_character_vocabs.csv')\n",
    "    model = torch.load(model_path, map_location=lambda storage, _: storage).module.to(device)\n",
    "\n",
    "    def parse(signal):\n",
    "        feature = torchaudio.compliance.kaldi.fbank(\n",
    "            waveform=torch.tensor(signal).unsqueeze(0),\n",
    "            num_mel_bins=80,\n",
    "            frame_length=20,\n",
    "            frame_shift=10,\n",
    "            window_type='hamming'\n",
    "        ).transpose(0, 1).numpy()\n",
    "        feature -= feature.mean()\n",
    "        feature /= np.std(feature)\n",
    "        return torch.FloatTensor(feature).transpose(0, 1)\n",
    "\n",
    "    def revise(sentence):\n",
    "        words = sentence.split()\n",
    "        result = []\n",
    "        for word in words:\n",
    "            tmp = word[0] + ''.join([word[i] for i in range(1, len(word)) if word[i] != word[i - 1]])\n",
    "            if tmp == '스로':\n",
    "                tmp = '스스로'\n",
    "            result.append(tmp)\n",
    "        return ' '.join(result)\n",
    "\n",
    "    def __new__(cls, path):\n",
    "        wav_data, sr = librosa.load(path, sr=16000)\n",
    "        feature = cls.parse(wav_data)\n",
    "        input_length = torch.LongTensor([len(feature)])\n",
    "\n",
    "        y_hats = cls.model.recognize(feature.unsqueeze(0), input_length)\n",
    "        sentence = cls.vocab.label_to_string(y_hats.cpu().detach().numpy())[0]\n",
    "        return cls.revise(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "이거 배달이 잘못 온 거 같아요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이게 배달이 잘못둔 거 같아 영.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STT('G:\\내 드라이브\\lincall-ai\\\\audio0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "class STT:\n",
    "    recognizer = sr.Recognizer()\n",
    "    recognizer.energy_threshold = 300\n",
    "\n",
    "    def __new__(cls, path):\n",
    "        korean_audio = sr.AudioFile(path)\n",
    "\n",
    "        with korean_audio as source:\n",
    "            data = cls.recognizer.record(source)\n",
    "\n",
    "        return cls.recognizer.recognize_google(audio_data=data, language=\"ko-KR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'배달이 잘못 온 거 같아요'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STT('G:\\내 드라이브\\lincall-ai\\\\audio0.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c45a5d2cedf03315b605f781a38921e17d7dbdeb292664a5e6f38421aada0de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
